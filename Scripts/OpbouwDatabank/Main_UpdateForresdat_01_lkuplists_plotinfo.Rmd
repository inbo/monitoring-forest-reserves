---
title: "Update forresdat - lookuplists en plotinfo"
author: "Anja Leyman"
date: "`r Sys.Date()`"
output: 
  html_document:
    keep_md: FALSE
    number_sections: yes
    fig_caption: yes
    code_folding: hide
    toc: TRUE
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---


```{r Rm, eval = FALSE}
rm(list=ls())
```

```{r Setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  eval = FALSE,  # FALSE: dan kan ik knitten zonder dat er iets gebeurt
  message = FALSE,
  warning = FALSE, 
  fig.width = 9,
  fig.align = TRUE)

library(here)

# libraries & invoergegevens
source(here::here("scripts/Setup.R"))

```



```{r juiste_forrescalc}
# !!! eerst zeker 'install.packages("forrescalc")
# zodat data goede release krijgt!
# zie mail 7/10/24 van Els L.
# soms een andere branch nodig als Els nog iets moet fixen, maar als ik naar forresdat 
# wil wegschrijven, moet ik officiële versie van forresclac gebruiken

install.packages("forrescalc")
```



# Vraagstelling
DOEL van dit script is een update van forresdat gegevens naar 

- forresdat-folder (nadien nog te pushen naar github)
- BR_analysedb.accdb op de c-schijf
- output-folders op de c-schijf "_plot-level-data" en "_tree-level-data"
- teamdrive-folders "_plot-level-data" en "_tree-level-data"

Kersselaerspleyn blijkt op meerdere vlakken uitzonderingen te bevatten.
Deze uitzonderingen worden na het inladen van de data gecorrigeerd. 

<!-- - path_to_forresdat_data is "`r path_to_forresdat_data`"        -->

```{r results='hold', eval=TRUE}
print(paste0("path_to_fieldmap is ", path_to_fieldmap))
print(paste0("path_to_strata_db is ", path_to_strata_db))

print(paste0("path_to_teamdrive is ", path_to_teamdrive))
print(paste0("path_to_dataverwerking_teamdrive is ", path_to_dataverwerking_teamdrive))

print(paste0("path_to_forresdat_data is ", path_to_forresdat_data))
print(paste0("path_to_analysis_set_db is ", path_to_analysis_set_db))

print(paste0("path_to_plotlevel_csv is ", path_to_plotlevel_csv))
print(paste0("path_to_treelevel_csv is ", path_to_treelevel_csv))
print(paste0("path_to_lulists_csv is ", path_to_lulists_csv))
print(paste0("path_to_dbResults is ", path_to_dbResults))
print(paste0("path_to_plotlevel_gdrive is ", path_to_plotlevel_gdrive))

print(paste0("dbExterneData is ", dbExterneData))
print(paste0("path_to_height_models is ", path_to_height_models))
print(paste0("path_to_heightmodels_teamdrive is ", path_to_heightmodels_teamdrive))

print(paste0("path_to_datarequests_gdrive is ", path_to_datarequests_gdrive))
print(paste0("path_to_shp is ", path_to_shp))

```

# SVZ

- 25/9/2024: eerste keer op basis van een kopie van de volledige moederdatabank
(te vinden als zip-file op citrix onder "...\Projects\PRJ_BosEco\PRJ_ALG_FIELDMAP\FM_MDB BOSRESERVATEN")    

- 7/10/2024: qTotalCover toegevoegd aan forresdat


# Update lookuplijsten - INDIEN GEWIJZIGD

Enkel indien de q-tabellen gewijzigd zijn.
Enkel de gewijzigde tabellen vermelden.

Forresdat opnieuw opgevuld op 24/9/2024

## Rechtstreeks van fieldmap-db naar forresdat - ok

Sinds 2024 als csv en metadata in één grote json-file:   

- Op c-schijf onder `r path_to_git_forresdat`.
- Op github onder [https://github.com/inbo/forresdat](https://github.com/inbo/forresdat)

```{r lkp_save_git, eval=FALSE}
# remove_last_commit_forresdat(path_to_git_forresdat)  
# als er iets fouts gebeurt, op deze manier laatste commit verwijderen 
# !! voordat er gepusht is !!

from_access_to_forresdat(
  database = path_to_fieldmap_db,
  tables = c("qAliveDead", "qSpecies", "qHerbSpecies240810", 
             "qHeightClass_regeneration", "qnumber_regeneration_classes", 
             "qdecaystage",
             "qcommonremark", 
             "qiufrosocialstatus", "qiufroheight", "qiufrovitality", 
             "qiufrosocialstatus_shoots", "qiufroheight_shoots", "qiufrovitality_shoots",
             "qtotalCover", "qBrowsIndex", "qCoverHerbs", 
             "qPlotType", 
             "qIntactSnag", "qIndShootCop", "qVdagnVfm",
             "qCrownVolRedu","qBranchLenghtReduction"),
  repo_path = path_to_git_forresdat,
  metadata_path = paste0(path_to_metadata, "_metadata_lookuplists.xlsx"),
  strict = TRUE
)
# !!!! argument "strict": keep default TRUE to update data without structural changes,
#    change to FALSE only if tables are structurally changed
#          (e.g. additional column, change in sorting order,...)


# éénmalig: remove_table_forresdat("q_plot_type", path_to_git_forresdat)

```

Enkele makkelijke functies uit forrescalc:    

- `remove_last_commit_forresdat(path_to_git_forresdat)`   
- `remove_table_forresdat("q_plot_type", path_to_git_forresdat)`   

```{r eval=FALSE}
?remove_last_commit_forresdat
?remove_table_forresdat
```



## Vanuit forresdat naar analysedb

Functie `from_forresdat_to_access()` is gebaseerd op de functies `read_forresdat()` en `read_forresdat_table()`. 
Deze kunnen enkel data binnenhalen van de main branch, niet de develop branch.
Dus tijdelijk met `save_results_access()` werken.

Op termijn zou dat in orde moeten geraken (gevraagd via mail 26/9/24 aan Els): optie om ook uit develop branch 
data binnen te kunnen halen.


```{r eval = FALSE}
# ?from_forresdat_to_access

# file_names <- list.files(path = paste0(path_to_git_forresdat, "/data")
#                          , pattern = "\\.csv$") %>% 
#   gsub("\\.csv$", "", .)
# file_names
from_forresdat_to_access(tables = c("qalive_dead", "qbranch_lenght_reduction",  
                                    "qbrows_index", "qcommonremark", "qcover_herbs" , 
                                    "qcrown_vol_redu", "qdecaystage", 
                                    "qheight_class_regeneration", "qherb_species240810", 
                                    "qind_shoot_cop", "qintact_snag", "qiufroheight",
                                    "qiufroheight_shoots", "qiufrosocialstatus", 
                                    "qiufrosocialstatus_shoots", "qiufrovitality", 
                                    "qiufrovitality_shoots", "qnumber_regeneration_classes", 
                                    "qplot_type", "qspecies" , "qvdagn_vfm"),
                         database = path_to_analysis_set_db,
                         remove_tables = TRUE,
                         join_plotinfo = FALSE)

read_forresdat_table(tablename = "qalive_dead", join_plotinfo = FALSE)
read_forresdat_table(tablename = "qcommonremark", join_plotinfo = FALSE)

library(frictionless)
datapackage <- frictionless::read_package(file.path(path_to_forresdat_data, "datapackage.json"))
resources(datapackage)
```
 
 
## List met lkp-lists naar analysedb - ok 
 
Indien functie `from_forresdat_to_access` niet werkt, functie `save_results_access`
gebruiken.
 
Daarvoor is een list nodig van de weg te schrijven tabellen.
 
```{r list_lkp}
# inladen
con <- odbcConnectAccess2007(path_to_fieldmap_db)

  qIndShootCop <- sqlFetch(con, "qIndShootCop", stringsAsFactors = FALSE)
  # deadw_test <- sqlFetch(con, "Deadwood_3eSET", stringsAsFactors = FALSE)
  qAliveDead <- sqlFetch(con, "qAliveDead", stringsAsFactors = FALSE)
  qSpecies <- sqlFetch(con, "qSpecies", stringsAsFactors = FALSE)
  qDecaystage <- sqlFetch(con, "qdecaystage", stringsAsFactors = FALSE)
  qIntactSnag <- sqlFetch(con, "qIntactSnag", stringsAsFactors = FALSE)
  qVdagnVfm <- sqlFetch(con, "qVdagnVfm", stringsAsFactors = FALSE)
  
  qtotalCover<- sqlFetch(con, "qtotalCover", stringsAsFactors = FALSE)
  qHerbSpecies240810<- sqlFetch(con, "qHerbSpecies240810", stringsAsFactors = FALSE)
  qCoverHerbs <- sqlFetch(con, "qCoverHerbs", stringsAsFactors = FALSE)
  qBrowsIndex <- sqlFetch(con, "qBrowsIndex", stringsAsFactors = FALSE)
  
  qHeightClass_regeneration <- sqlFetch(con, "qHeightClass_regeneration", stringsAsFactors = FALSE)
  qnumber_regeneration_classes <- sqlFetch(con, "qnumber_regeneration_classes", stringsAsFactors = FALSE)
  
  qcommonremark <- sqlFetch(con, "qcommonremark", stringsAsFactors = FALSE)
  qCrownVolRedu <- sqlFetch(con, "qCrownVolRedu", stringsAsFactors = FALSE)
  qBranchLenghtReduction <- sqlFetch(con, "qBranchLenghtReduction", stringsAsFactors = FALSE)

  qiufroheight <- sqlFetch(con, "qiufroheight", stringsAsFactors = FALSE)
  qiufroheight_shoots <- sqlFetch(con, "qiufroheight_shoots", stringsAsFactors = FALSE)
  qiufrovitality <- sqlFetch(con, "qiufrovitality", stringsAsFactors = FALSE)
  qiufrovitality_shoots <- sqlFetch(con, "qiufrovitality_shoots", stringsAsFactors = FALSE)
  qiufrosocialstatus <- sqlFetch(con, "qiufrosocialstatus", stringsAsFactors = FALSE)
  qiufrosocialstatus_shoots <- sqlFetch(con, "qiufrosocialstatus_shoots", stringsAsFactors = FALSE)
  
odbcClose(con)

# in lijst stoppen
list_lkp <- list(qIndShootCop = qIndShootCop, qAliveDead = qAliveDead, qSpecies = qSpecies, 
                 qDecaystage = qDecaystage, qIntactSnag = qIntactSnag, 
                 qVdagnVfm = qVdagnVfm,
                 qCrownVolRedu = qCrownVolRedu, qBranchLenghtReduction = qBranchLenghtReduction,
                 qiufroheight = qiufroheight, qiufroheight_shoots = qiufroheight_shoots,
                 qiufrosocialstatus = qiufrosocialstatus, 
                 qiufrosocialstatus_shoots = qiufrosocialstatus_shoots,
                 qiufrovitality = qiufrovitality, 
                 qiufrovitality_shoots = qiufrovitality_shoots,
                 qtotalCover = qtotalCover,
                 qHerbSpecies240810 = qHerbSpecies240810, 
                 qCoverHerbs = qCoverHerbs, qBrowsIndex = qBrowsIndex, 
                 qHeightClass_regeneration = qHeightClass_regeneration, 
                 qnumber_regeneration_classes = qnumber_regeneration_classes,
                 qcommonremark = qcommonremark
                 )

# Blijkbaar Value3 als logical geëxporteerd verderop
# => all Value3 as character when it is logical (sometimes integer: qspecies, ...)
# lapply: same function over all elements of the list
list_lkp2 <- lapply(list_lkp, function(df) {
  df %>%
    mutate(Value3 = ifelse(is.logical(Value3), as.character(Value3), Value3))  # Modify Value3 field
})

list_lkp <- list_lkp2

```
 

```{r eval = FALSE}
# list_lkp aangemaakt in hogere chunck, bevat alle LU-lijsten
# test
# list_lkp <- list(qind_shoot_cop = qIndShootCop, qalive_dead = qAliveDead)

# ?save_results_access
save_results_access(
  results = list_lkp,
  database = path_to_analysis_set_db,
  remove_tables = TRUE
)

```


## Afzonderlijke files - ok

Csv-files opslaan op c-schijf en in teamdrive `r path_to_lulists_gdrive` (zonder json).

```{r eval = FALSE}
path_to_lulists_gdrive
path_to_lulists_csv

save_results_csv(
    results = list_lkp,
    output_dir = path_to_lulists_csv)

# gdrive
save_results_csv(
    results = list_lkp,
    output_dir = path_to_lulists_gdrive)
```


# Plotinfo 

Plotinfo samenstellen, zijnde plottype, naam forest_reserve en info over survey en data al dan niet processed.
Wegschrijven naar git, access en opslaan als csv

- Enkel deze waar een dendro-opname gebeurd is (survey_trees = TRUE)
- Zowel verwerkte als niet verwerkte plots (processed = TRUE/FALSE)


```{r plotinfo_load}
plotinfo <- load_plotinfo(database = path_to_fieldmap_db, processed = FALSE)
names(plotinfo)

plotinfo <- plotinfo %>% 
  filter(survey_trees == TRUE & !is.na(survey_trees))
```

```{r check_processed}
table(plotinfo$forest_reserve, plotinfo$data_processed)
# table(plotinfo$forest_reserve, plotinfo$data_processed)

plotinfo %>% filter(data_processed==FALSE)
```

```{r check_not_processed}
check_survey_trees_summ <- plotinfo %>% 
  group_by(forest_reserve, plottype, period, survey_trees, data_processed) %>% 
  summarize(n_plots = n(),
            min_plotid = min(plot_id),
            max_plotid = max(plot_id)) %>% 
  ungroup()

check_survey_trees_summ %>% 
  filter(survey_trees == TRUE & data_processed == FALSE)
```

Wijnendalebos: 4 plots uit periode 1 die niet verder meegenomen werden in de verwerking - ok
Kersselaerspleyn: plot 1999: Rgister+: OK, niet mee te nemen
Withoefse heide: 3eSET (dd 13/7/2022), verwerking is uitgesteld naar 2025

forest_reserve = NA? : 10 plots 700-780, 3de decade: Heirnisse, nog niet verwerkt
Deels wel al survey_trees ingevuld
=> deze verwijderen om geen verwarring te creëren

```{r}
plotinfo %>% filter(is.na(forest_reserve))

plotinfo %>% filter(is.na(forest_reserve)) %>% distinct(plot_id)
```

```{r}
# omgekeerd geen plots die processed zijn, en géén survey_trees
plotinfo %>%  filter(data_processed & !survey_trees) %>% nrow() == 0
```

## Correctie niet volledig afgewerkte plots

forest_reserve = NA: 10 plots 700-780, 3de decade: Heirnisse, nog niet verwerkt
Deels wel al survey_trees ingevuld
=> deze verwijderen om geen verwarring te creëren

```{r}
plotinfo <- plotinfo %>% filter(!is.na(forest_reserve))
```


## Year_dendro

Year_dendro = jaar van groeiseizoen
Grens ligt op 1/5.
Soms dendro effectief in twee verschillende groeiseizoenen opgemeten - OK

```{r check}
names(plotinfo)

year_range <- plotinfo %>% 
  group_by(forest_reserve, period) %>% 
  summarize(min_year = min(year_dendro), 
            max_year = max(year_dendro),
            year_range = paste0(min_year, " - ", max_year)) %>% 
  ungroup()

t <- year_range %>% 
  filter(min_year != max_year)
t_ <- t %>% 
  left_join(plotinfo)

```

# Correctie Kersselaerspleyn

## Survey_deadw - CP's 1eSET

CP's deadwood 1eSET (2000): opname uitgevoerd, maar niet geïmporteerd in FieldMap.
Verwerkt door Luc DK ikv eerste monitoringrapport, en gegevens uit het monitoringrapport
("CP_Kerss_logs_2000.xlsx" in folder "C:/03_BR/1_DataVerwerkingBR/Data/Meetgegevens/logs_CPs_Kerss_2000")
opgehaald mbv script "Main_UpdateForresdat_02_dendro.Rmd".

```{r CORR_survey_deadw_CP_Kerss}
# plotinfo %>% filter(forest_reserve == "Kersselaerspleyn" & plottype == "CP" & period == 1) %>% nrow()
# 64

# plotinfo %>% filter(forest_reserve == "Kersselaerspleyn" & plottype == "CP" 
#                     & period == 1 & survey_trees) %>% nrow()
# 53

plotinfo_ <- plotinfo %>% 
  dplyr::mutate(survey_deadw = ifelse(forest_reserve == "Kersselaerspleyn" & plottype == "CP" 
                    & period == 1 & survey_trees
                    , TRUE
                    , survey_deadw))

plotinfo_ %>% dplyr::filter(forest_reserve == "Kersselaerspleyn" & plottype == "CP" 
                     & period == 1 & survey_trees) %>% head()

plotinfo <- plotinfo_

```


# Export plotinfo

```{r plotinfo_save_git, eval=FALSE}
save_results_forresdat(
  results = list(plotinfo = plotinfo)
  , repo_path = path_to_git_forresdat
  , metadata_path = paste0(path_to_metadata, "_metadata_plotinfo.xlsx")
  , strict = TRUE
  # , strict = FALSE
  )

```


```{r plotinfo_save_access_csv, eval=FALSE}
save_results_access(
  results = list(plotinfo = plotinfo),
  database = path_to_analysis_set_db,
  remove_tables = TRUE
)
# !!  als niet lukt, dan staat tabel mogelijks nog open in db

save_results_csv(
    results = list(plotinfo = plotinfo),
    output_dir = path_to_plotlevel_csv
  )

# gdrive
save_results_csv(
    results = list(plotinfo = plotinfo),
    output_dir = path_to_plotlevel_gdrive
  )
```

**Na update van forresdat, project "forresdat" openen en alles naar de cloud pushen**
**Eventueel ook access op gdrive plaatsen**
